{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd40429a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-25T18:59:57.537283Z",
     "iopub.status.busy": "2022-01-25T18:59:57.536086Z",
     "iopub.status.idle": "2022-01-25T18:59:59.141758Z",
     "shell.execute_reply": "2022-01-25T18:59:59.141172Z",
     "shell.execute_reply.started": "2022-01-25T17:59:24.966276Z"
    },
    "papermill": {
     "duration": 1.621426,
     "end_time": "2022-01-25T18:59:59.141880",
     "exception": false,
     "start_time": "2022-01-25T18:59:57.520454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e200707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T18:59:59.167559Z",
     "iopub.status.busy": "2022-01-25T18:59:59.167117Z",
     "iopub.status.idle": "2022-01-25T18:59:59.170469Z",
     "shell.execute_reply": "2022-01-25T18:59:59.170893Z",
     "shell.execute_reply.started": "2022-01-25T17:59:26.706501Z"
    },
    "papermill": {
     "duration": 0.017449,
     "end_time": "2022-01-25T18:59:59.171039",
     "exception": false,
     "start_time": "2022-01-25T18:59:59.153590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "punc = string.punctuation + '•'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23de0f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T18:59:59.200852Z",
     "iopub.status.busy": "2022-01-25T18:59:59.200356Z",
     "iopub.status.idle": "2022-01-25T18:59:59.214897Z",
     "shell.execute_reply": "2022-01-25T18:59:59.215301Z",
     "shell.execute_reply.started": "2022-01-25T17:59:26.713093Z"
    },
    "papermill": {
     "duration": 0.033593,
     "end_time": "2022-01-25T18:59:59.215451",
     "exception": false,
     "start_time": "2022-01-25T18:59:59.181858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contractions_dict = {\"ain't\": 'are not',\n",
    " \"'s\": ' is',\n",
    " \"aren't\": 'are not',\n",
    " \"can't\": 'cannot',\n",
    " \"can't've\": 'cannot have',\n",
    " \"'cause\": 'because',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"couldn't've\": 'could not have',\n",
    " \"didn't\": 'did not',\n",
    " \"doesn't\": 'does not',\n",
    " \"don't\": 'do not',\n",
    " \"hadn't\": 'had not',\n",
    " \"hadn't've\": 'had not have',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he'd\": 'he would',\n",
    " \"he'd've\": 'he would have',\n",
    " \"he'll\": 'he will',\n",
    " \"he'll've\": 'he will have',\n",
    " \"how'd\": 'how did',\n",
    " \"how'd'y\": 'how do you',\n",
    " \"how'll\": 'how will',\n",
    " \"i'd\": 'i would',\n",
    " \"i'd've\": 'i would have',\n",
    " \"i'll\": 'i will',\n",
    " \"i'll've\": 'i will have',\n",
    " \"i'm\": 'i am',\n",
    " \"i've\": 'i have',\n",
    " \"isn't\": 'is not',\n",
    " \"it'd\": 'it would',\n",
    " \"it'd've\": 'it would have',\n",
    " \"it'll\": 'it will',\n",
    " \"it'll've\": 'it will have',\n",
    " \"let's\": 'let us',\n",
    " \"ma'am\": 'madam',\n",
    " \"mayn't\": 'may not',\n",
    " \"might've\": 'might have',\n",
    " \"mightn't\": 'might not',\n",
    " \"mightn't've\": 'might not have',\n",
    " \"must've\": 'must have',\n",
    " \"mustn't\": 'must not',\n",
    " \"mustn't've\": 'must not have',\n",
    " \"needn't\": 'need not',\n",
    " \"needn't've\": 'need not have',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"oughtn't've\": 'ought not have',\n",
    " \"shan't\": 'shall not',\n",
    " \"sha'n't\": 'shall not',\n",
    " \"shan't've\": 'shall not have',\n",
    " \"she'd\": 'she would',\n",
    " \"she'd've\": 'she would have',\n",
    " \"she'll\": 'she will',\n",
    " \"she'll've\": 'she will have',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"shouldn't've\": 'should not have',\n",
    " \"so've\": 'so have',\n",
    " \"that'd\": 'that would',\n",
    " \"that'd've\": 'that would have',\n",
    " \"there'd\": 'there would',\n",
    " \"there'd've\": 'there would have',\n",
    " \"they'd\": 'they would',\n",
    " \"they'd've\": 'they would have',\n",
    " \"they'll\": 'they will',\n",
    " \"they'll've\": 'they will have',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"to've\": 'to have',\n",
    " \"wasn't\": 'was not',\n",
    " \"we'd\": 'we would',\n",
    " \"we'd've\": 'we would have',\n",
    " \"we'll\": 'we will',\n",
    " \"we'll've\": 'we will have',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"weren't\": 'were not',\n",
    " \"what'll\": 'what will',\n",
    " \"what'll've\": 'what will have',\n",
    " \"what're\": 'what are',\n",
    " \"what've\": 'what have',\n",
    " \"when've\": 'when have',\n",
    " \"where'd\": 'where did',\n",
    " \"where've\": 'where have',\n",
    " \"who'll\": 'who will',\n",
    " \"who'll've\": 'who will have',\n",
    " \"who've\": 'who have',\n",
    " \"why've\": 'why have',\n",
    " \"will've\": 'will have',\n",
    " \"won't\": 'will not',\n",
    " \"won't've\": 'will not have',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"wouldn't've\": 'would not have',\n",
    " \"y'all\": 'you all',\n",
    " \"y'all'd\": 'you all would',\n",
    " \"y'all'd've\": 'you all would have',\n",
    " \"y'all're\": 'you all are',\n",
    " \"y'all've\": 'you all have',\n",
    " \"you'd\": 'you would',\n",
    " \"you'd've\": 'you would have',\n",
    " \"you'll\": 'you will',\n",
    " \"you'll've\": 'you will have',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have',\n",
    "' afaik ': ' as far as i know ',\n",
    " ' afk ': ' away from keyboard',\n",
    " ' asap ': ' as soon as possible',\n",
    " ' atk ': ' at the keyboard',\n",
    " ' atm ': ' at the moment',\n",
    " ' bak ': ' back at keyboard ',\n",
    " ' bbl ': ' be back later ',\n",
    " ' bbs ': ' be back soon ',\n",
    " ' bfn ': ' bye for now ',\n",
    " ' b4n ': ' bye for now ',\n",
    " ' brb ': ' be right back ',\n",
    " ' brt ': ' be right there ',\n",
    " ' btw ': ' by the way ',\n",
    " ' b4 ': ' before ',\n",
    " ' cu ': ' see you ',\n",
    " ' cul8r ': ' see you later ',\n",
    " ' cya ': ' see you ',\n",
    " ' faq ': ' frequently asked questions ',\n",
    " ' fc ': ' fingers crossed ',\n",
    " ' fwiw ': \" for what it is worth \",\n",
    " ' fyi ': ' for your information ',\n",
    " ' gal ': ' get a life ',\n",
    " ' gg ': ' good game ',\n",
    " ' gn ': ' good night ',\n",
    " 'gmta': 'great minds think alike',\n",
    " ' gr8 ': ' great! ',\n",
    " ' g9 ': ' genius ',\n",
    " ' ic ': ' i see ',\n",
    " ' icq ': ' i seek you ',\n",
    " 'ilu': ' i love you',\n",
    " 'imho': ' in my humble opinion',\n",
    " ' imo ': ' in my opinion ',\n",
    " ' iow ': ' in other words ',\n",
    " 'irl': 'in real life',\n",
    " ' ldr ': ' long distance relationship ',\n",
    " 'lmao': ' laugh my ass off',\n",
    " ' lol ': ' laughing out loud ',\n",
    " 'ltns': ' long time no see',\n",
    " ' l8r ': ' later ',\n",
    " ' mte ': ' my thoughts exactly ',\n",
    " ' m8 ': ' mate ',\n",
    " ' nrn ': ' no reply necessary ',\n",
    " ' oic ': ' oh i see ',\n",
    " ' pita ': ' pain in the ass ',\n",
    " ' prt ': ' party ',\n",
    " ' prw ': ' parents are watching ',\n",
    " 'qpsa?': 'que pasa?',\n",
    " 'rofl': 'rolling on the floor laughing',\n",
    " 'roflol': 'rolling on the floor laughing out loud',\n",
    " 'rotflmao': 'rolling on the floor laughing my ass off',\n",
    " ' sk8 ': ' skate ',\n",
    " ' stats ': ' your sex and age ',\n",
    " ' asl ': ' age, sex, location ',\n",
    " ' thx ': ' thank you ',\n",
    " 'ttfn': 'ta-ta for now!',\n",
    " 'ttyl': ' talk to you later',\n",
    " ' u ': ' you ',\n",
    " 'u2': ' you too',\n",
    " 'u4e': ' yours for ever',\n",
    " ' wb ': ' welcome back ',\n",
    " 'wtf': ' what the fuck',\n",
    " 'wtg': ' way to go!',\n",
    " 'wuf': ' where are you from?',\n",
    " ' w8 ': ' wait ',\n",
    "' pov ':' point of view '}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b32907d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T18:59:59.240575Z",
     "iopub.status.busy": "2022-01-25T18:59:59.240073Z",
     "iopub.status.idle": "2022-01-25T18:59:59.247399Z",
     "shell.execute_reply": "2022-01-25T18:59:59.247747Z",
     "shell.execute_reply.started": "2022-01-25T17:59:26.747119Z"
    },
    "papermill": {
     "duration": 0.021156,
     "end_time": "2022-01-25T18:59:59.247877",
     "exception": false,
     "start_time": "2022-01-25T18:59:59.226721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_cleaning(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = ' '.join(['' if 'http' in words or 'www' in words or '.jpeg' in words or '.jpg' in words or '.png' in words or '.zip' in words or 'wikipeida_talk' in words or '@' in words or '•' in words or '&' in words or '\\n' in words else words for words in txt.split() ]) #html .jpg .png zip wikipeida_Talk removal      \n",
    "    #mail\n",
    "    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    match = re.findall(pattern, txt)\n",
    "    try:\n",
    "        txt = txt.replace(match[0],'') #mail removal code\n",
    "    except:\n",
    "        pass\n",
    "    txt = ''.join([char for char in txt if char not in punc+'1234567890' ]) #Punctuation & IP removal\n",
    "    txt = re.sub(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1',txt)\n",
    "    txt = re.sub(r'([*!?\\']+)',r' \\1 ',txt)\n",
    "    txt = re.sub(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1', txt)    \n",
    "    txt = re.sub(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1',txt)\n",
    "    # Expanding Contractions in the comments\n",
    "    txt = expand_contractions(txt)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    txt = emoji_pattern.sub(r'', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba2e72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T18:59:59.274143Z",
     "iopub.status.busy": "2022-01-25T18:59:59.273609Z",
     "iopub.status.idle": "2022-01-25T19:00:01.616456Z",
     "shell.execute_reply": "2022-01-25T19:00:01.616075Z",
     "shell.execute_reply.started": "2022-01-25T17:59:26.766722Z"
    },
    "papermill": {
     "duration": 2.357805,
     "end_time": "2022-01-25T19:00:01.616561",
     "exception": false,
     "start_time": "2022-01-25T18:59:59.258756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1      6360\n",
       "3      4209\n",
       "2      3480\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "Name: added, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\n",
    "df['added'] = df['toxic']+df['severe_toxic']+df['obscene']+df['threat']+df['insult']+df['identity_hate']\n",
    "df['added'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6018e519",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-01-25T19:00:01.645719Z",
     "iopub.status.busy": "2022-01-25T19:00:01.644964Z",
     "iopub.status.idle": "2022-01-25T19:00:01.682211Z",
     "shell.execute_reply": "2022-01-25T19:00:01.681698Z",
     "shell.execute_reply.started": "2022-01-25T17:59:28.975738Z"
    },
    "papermill": {
     "duration": 0.053596,
     "end_time": "2022-01-25T19:00:01.682317",
     "exception": false,
     "start_time": "2022-01-25T19:00:01.628721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6360\n",
       "3    4209\n",
       "2    3480\n",
       "4    1760\n",
       "5     385\n",
       "6      31\n",
       "Name: added, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['added'] != 0]\n",
    "df['added'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9b2888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:00:01.713694Z",
     "iopub.status.busy": "2022-01-25T19:00:01.712683Z",
     "iopub.status.idle": "2022-01-25T19:00:01.738610Z",
     "shell.execute_reply": "2022-01-25T19:00:01.738994Z",
     "shell.execute_reply.started": "2022-01-25T17:59:29.019009Z"
    },
    "papermill": {
     "duration": 0.044854,
     "end_time": "2022-01-25T19:00:01.739140",
     "exception": false,
     "start_time": "2022-01-25T19:00:01.694286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>added</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  added  \\\n",
       "6       1           2.5     0.16     0.0     0.1            0.0      4   \n",
       "12      1           0.0     0.00     0.0     0.0            0.0      1   \n",
       "\n",
       "      target  \n",
       "6   0.626667  \n",
       "12  0.166667  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['severe_toxic'] = df.severe_toxic * 2.5\n",
    "df['insult'] = df.insult * 0.1\n",
    "df['identity_hate'] = df.identity_hate * 2.5\n",
    "df['toxic'] = df.toxic * 1\n",
    "df['threat'] = df.threat * 1.5\n",
    "df['obscene'] = df.obscene * 0.16\n",
    "\n",
    "df['target'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].mean(axis=1)\n",
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9b5063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:00:01.827463Z",
     "iopub.status.busy": "2022-01-25T19:00:01.804242Z",
     "iopub.status.idle": "2022-01-25T19:01:23.998508Z",
     "shell.execute_reply": "2022-01-25T19:01:23.998105Z",
     "shell.execute_reply.started": "2022-01-25T17:59:29.053761Z"
    },
    "papermill": {
     "duration": 82.247469,
     "end_time": "2022-01-25T19:01:23.998619",
     "exception": false,
     "start_time": "2022-01-25T19:00:01.751150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "        token = nltk.word_tokenize(text)\n",
    "        return token\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x : text_cleaning(x))\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x : tokenize(x))\n",
    "\n",
    "stpw = nltk.corpus.stopwords.words('english')\n",
    "def rmstp(text):\n",
    "    tt = [char.lower() for char in text if char not in stpw ]\n",
    "    return tt\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x:rmstp(x))\n",
    "#df.head(10)\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def rmstmer(text):\n",
    "    tt = [lemmatizer.lemmatize(char,tag_map[j[0]]) for char,j in pos_tag(text)]\n",
    "    return tt\n",
    "df['comment_text'] = df['comment_text'].apply(lambda x:rmstmer(x))\n",
    "#print(df.head())\n",
    "df['comment_text'] = [\" \".join(i) for i in df['comment_text']]\n",
    "#df.head()\n",
    "df = df[['comment_text','target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa78182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:01:24.031706Z",
     "iopub.status.busy": "2022-01-25T19:01:24.031002Z",
     "iopub.status.idle": "2022-01-25T19:01:24.033868Z",
     "shell.execute_reply": "2022-01-25T19:01:24.034396Z",
     "shell.execute_reply.started": "2022-01-25T18:00:32.052393Z"
    },
    "papermill": {
     "duration": 0.024001,
     "end_time": "2022-01-25T19:01:24.034557",
     "exception": false,
     "start_time": "2022-01-25T19:01:24.010556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hey talk exclusive group wp talibanswho good d...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bye dont look come think comming back tosser</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gay antisemmitian archangel white tiger meow g...</td>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>fuck filthy mother as dry</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text    target\n",
       "6                         cocksucker piss around work  0.626667\n",
       "12  hey talk exclusive group wp talibanswho good d...  0.166667\n",
       "16       bye dont look come think comming back tosser  0.166667\n",
       "42  gay antisemmitian archangel white tiger meow g...  0.626667\n",
       "43                          fuck filthy mother as dry  0.210000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da60d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:01:24.075154Z",
     "iopub.status.busy": "2022-01-25T19:01:24.074473Z",
     "iopub.status.idle": "2022-01-25T19:01:32.764435Z",
     "shell.execute_reply": "2022-01-25T19:01:32.764046Z",
     "shell.execute_reply.started": "2022-01-25T18:00:32.065538Z"
    },
    "papermill": {
     "duration": 8.711355,
     "end_time": "2022-01-25T19:01:32.764545",
     "exception": false,
     "start_time": "2022-01-25T19:01:24.053190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16225, 55046)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(analyzer='char_wb',ngram_range = (3,5),max_df=0.5,min_df=3)\n",
    "xvect = vect.fit_transform(df['comment_text'])\n",
    "y = df['target']\n",
    "Xvect = pd.DataFrame(xvect.toarray())\n",
    "Xvect.shape\n",
    "print(xvect.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6697f7fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:01:32.796673Z",
     "iopub.status.busy": "2022-01-25T19:01:32.796164Z",
     "iopub.status.idle": "2022-01-25T19:04:45.670752Z",
     "shell.execute_reply": "2022-01-25T19:04:45.671232Z",
     "shell.execute_reply.started": "2022-01-25T18:28:41.477627Z"
    },
    "papermill": {
     "duration": 192.893344,
     "end_time": "2022-01-25T19:04:45.671397",
     "exception": false,
     "start_time": "2022-01-25T19:01:32.778053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model_lr = Ridge(alpha = 0.5, normalize = False, tol = 0.001, \\\n",
    "              solver ='auto', random_state = 42).fit(Xvect,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440188e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:04:45.724741Z",
     "iopub.status.busy": "2022-01-25T19:04:45.723835Z",
     "iopub.status.idle": "2022-01-25T19:04:45.726808Z",
     "shell.execute_reply": "2022-01-25T19:04:45.725300Z"
    },
    "papermill": {
     "duration": 0.032207,
     "end_time": "2022-01-25T19:04:45.726925",
     "exception": false,
     "start_time": "2022-01-25T19:04:45.694718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestRegressor\\nmodel_lr = RandomForestRegressor(n_estimators=20,random_state=42).fit(Xvect,y)\\nmodel_lr.score(Xvect,y)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_lr = RandomForestRegressor(n_estimators=20,random_state=42).fit(Xvect,y)\n",
    "model_lr.score(Xvect,y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5d2f655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:04:45.768058Z",
     "iopub.status.busy": "2022-01-25T19:04:45.767371Z",
     "iopub.status.idle": "2022-01-25T19:04:45.770146Z",
     "shell.execute_reply": "2022-01-25T19:04:45.768587Z",
     "shell.execute_reply.started": "2022-01-25T18:33:30.309687Z"
    },
    "papermill": {
     "duration": 0.02651,
     "end_time": "2022-01-25T19:04:45.770271",
     "exception": false,
     "start_time": "2022-01-25T19:04:45.743761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nval_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\\npred1 = []\\npred2 = []\\nfrom tqdm import tqdm\\nfor a,b in tqdm(zip(val_df['less_toxic'],val_df['more_toxic'])):\\n    sample_1 = vect.transform([' '.join(rmstp(tokenize(text_cleaning(a))))])\\n    pred1.append(model_lr.predict(sample_1.toarray())[0])\\n    sample_2 = vect.transform([' '.join(rmstp(tokenize(text_cleaning(b))))])\\n    pred2.append(model_lr.predict(sample_2.toarray())[0])\\n    \\nval_df['sc1'] = pred1\\nval_df['sc2'] = pred2\\nprint((val_df['sc1'] < val_df['sc2']).mean())\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "val_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/validation_data.csv')\n",
    "pred1 = []\n",
    "pred2 = []\n",
    "from tqdm import tqdm\n",
    "for a,b in tqdm(zip(val_df['less_toxic'],val_df['more_toxic'])):\n",
    "    sample_1 = vect.transform([' '.join(rmstp(tokenize(text_cleaning(a))))])\n",
    "    pred1.append(model_lr.predict(sample_1.toarray())[0])\n",
    "    sample_2 = vect.transform([' '.join(rmstp(tokenize(text_cleaning(b))))])\n",
    "    pred2.append(model_lr.predict(sample_2.toarray())[0])\n",
    "    \n",
    "val_df['sc1'] = pred1\n",
    "val_df['sc2'] = pred2\n",
    "print((val_df['sc1'] < val_df['sc2']).mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6227861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:04:45.802201Z",
     "iopub.status.busy": "2022-01-25T19:04:45.801732Z",
     "iopub.status.idle": "2022-01-25T19:05:09.983600Z",
     "shell.execute_reply": "2022-01-25T19:05:09.984109Z"
    },
    "papermill": {
     "duration": 24.200692,
     "end_time": "2022-01-25T19:05:09.984264",
     "exception": false,
     "start_time": "2022-01-25T19:04:45.783572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7537/7537 [00:24<00:00, 313.69it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv')\n",
    "pred_df.head()\n",
    "sub_df =  pd.read_csv('../input/jigsaw-toxic-severity-rating/sample_submission.csv')\n",
    "sub_df.shape\n",
    "res = []\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(pred_df['text']):\n",
    "    sample_1 = vect.transform([' '.join(rmstp(tokenize(text_cleaning(i))))])\n",
    "    res.append(model_lr.predict(sample_1.toarray()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66332d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:05:10.155106Z",
     "iopub.status.busy": "2022-01-25T19:05:10.154581Z",
     "iopub.status.idle": "2022-01-25T19:05:10.157291Z",
     "shell.execute_reply": "2022-01-25T19:05:10.156721Z"
    },
    "papermill": {
     "duration": 0.083107,
     "end_time": "2022-01-25T19:05:10.157420",
     "exception": false,
     "start_time": "2022-01-25T19:05:10.074313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df['score'] = [i[0] for i in res]\n",
    "#sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a949b0ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-25T19:05:10.364247Z",
     "iopub.status.busy": "2022-01-25T19:05:10.363634Z",
     "iopub.status.idle": "2022-01-25T19:05:10.396906Z",
     "shell.execute_reply": "2022-01-25T19:05:10.397410Z"
    },
    "papermill": {
     "duration": 0.13791,
     "end_time": "2022-01-25T19:05:10.397571",
     "exception": false,
     "start_time": "2022-01-25T19:05:10.259661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('./submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 325.023572,
   "end_time": "2022-01-25T19:05:11.923120",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-25T18:59:46.899548",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
